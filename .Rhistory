knitr::opts_chunk$set(echo = TRUE)
require(dplyr)
require(xml2)
require(stringr)
require(XML)
require(rvest)
require(ggplot2)
str_detect(na.omit(str_extract(getLetterList(xml2_package_enlist_df$title, uppercase='A', lowercase=''), regex("^[A-Z\\d.]+$")))
, regex("[\\d]"))
getLetterList <- function(package_titles=c(), uppercase='', lowercase='') #case insensitive
{
if (uppercase=='' & lowercase=='')
{
stop("Empty letters given/unspecified")
} else
{
#return a vector
return(na.omit( #remove na before return
str_extract(package_titles
, regex(paste0("^[", tolower(lowercase), toupper(uppercase), "][\\w_.]+"))
)))
}
}
# return list of names of packages starting with `lower` or `upper`
# Test this example once you complete above function
# Assuming your dataframe is called df
# This prints all package names starting with `z` or `Z`
# letter='a'
# print(paste0("^[", tolower(letter), toupper(letter), "][\\w]+"))
# str_extract(xml2_package_enlist_df$title, regex(paste0("^[", tolower(letter), toupper(letter), "][\\w]+")))
lowercase='z'
uppercase='Z'
head(getLetterList(xml2_package_enlist_df$title, uppercase, lowercase))
knitr::opts_chunk$set(echo = TRUE)
require(dplyr)
require(xml2)
require(stringr)
require(XML)
require(rvest)
require(ggplot2)
url = './available_packages_by_name.html' #use file path instead of url
xml2_doc <- read_xml(url
, isHTML=T
)
# xml_name(xml2_doc) #html
# xml_children(xml2_doc)[2]
xml2_table <- xml_child(xml_child(xml2_doc, 2) #<body>
, 3 #<table>
)
# xml_child(xml2_table, 3)
xml_parsed_text <- xml_text(xml_children(xml_children(xml2_table)), trim=T) #pickup all text
xml_parsed_text <- xml_parsed_text[xml_parsed_text!=""] #remove "" element that disrupt order
# xml_parsed_text
xml2_package_title <- xml_parsed_text[c(T,F)] #pickup only even column elements
xml2_package_description <- xml_parsed_text[c(F,T)] #pickup only odd column elements
# length(xml2_package_title)
# length(xml2_package_description)
xml2_package_description <- str_replace_all(xml2_package_description, "\n", " ")
#check lengths before combine
# length(xml2_package_title)
# length(xml2_package_description)
xml2_package_enlist_df <- data.frame("title"=xml2_package_title
, "description"=xml2_package_description
)
nrow(xml2_package_enlist_df)
# filter(package_enlist_df, title=="") #there are 26 empty rows "" and " ", and so filter out
xml2_package_enlist_df <- filter(xml2_package_enlist_df, title!="") #remove line with the package title is empty
nrow(xml2_package_enlist_df)
#check
head(xml2_package_enlist_df)
tail(xml2_package_enlist_df)
# https://www.stat.berkeley.edu/~statcur/Workshop2/Presentations/XML.pdf
url = './available_packages_by_name.html' #use file path instead of url
xml_doc <- xmlTreeParse(url
, isHTML=T
, useInternalNodes = T
)
top = xmlRoot(xml_doc)
# xmlName(top) ##html
# names(top) ##head, body
# names(top[[2]][["table"]])
# names(top[["body"]][["table"]][["tr"]])
table_node <- xmlChildren(top)[c('body', 'table', "tr")][[1]] #<body>-><table>-><tr>
length(table_node)
# table_node[[6]]["tr"] #print each <tr></tr>
table_node_cat <- xmlSApply(table_node[[6]], function(x) xmlSApply(x, xmlValue))
#length(table_node_cat) ##33098
table_node_cat[1:6] #odd number is package name, even number is package description. some descriptions have a linebreak
#using recycle rule to pickup rapidly
package_title <- table_node_cat[c(T,F)] #pickup only odd column elements
package_description <- table_node_cat[c(F,T)] #pickup only even column elements
# package_title[1:10]
# package_description[1:10]
#some package_description have unncessary linebreak ("\n") and so replace it
package_description <- str_replace_all(package_description, "\n", " ")
# package_description
#check lengths before combine
length(package_title)
length(package_description)
#cbind("title"=package_title, "description"=package_description)
package_enlist_df <- data.frame("title"=package_title
, "description"=package_description
)
nrow(package_enlist_df)
# filter(package_enlist_df, title=="") #there are 26 empty rows "" and " ", and so filter out
package_enlist_df <- filter(package_enlist_df, title!="") #remove line with the package title is empty
nrow(package_enlist_df)
#a dataframe for package titles and the descriptions ready
head(package_enlist_df)
tail(package_enlist_df)
#print(letters) #lowercase
#print(LETTERS) #uppercase
title_tolower <- tolower(xml2_package_enlist_df$title) #convert to lowercase
# head(title_tolower)
# length(title_tolower)
cap_count_df <- as.data.frame(table(str_extract(title_tolower, regex("^[a-z]"))), stringsAsFactors = FALSE) #drop level
#stringsAsFactors = FALSE or use droplevels(cap_count_df)
head(cap_count_df)
cap_count_df <- arrange(cap_count_df, desc(Freq))
head(cap_count_df)
# reorder(cap_count_df$Var1, cap_count_df$Freq, desc(x)) #check how to use reorder
# levels(cap_count_df$Var1)
cap_count_df$Var1 <- factor(cap_count_df$Var1, levels=cap_count_df$Var1) #fix level order as factor
levels(cap_count_df$Var1)
ggplot(data=cap_count_df, aes(x=Var1, y=Freq)
) +
geom_bar(stat="identity") +
labs(title="Frequency of the first letter in package titles"
, x="Beginning alpabet"
, y="Frequency"
)
getLetterList <- function(package_titles=c(), uppercase='', lowercase='') #case insensitive
{
if (uppercase=='' & lowercase=='')
{
stop("Empty letters given/unspecified")
} else
{
#return a vector
return(na.omit( #remove na before return
str_extract(package_titles
, regex(paste0("^[", tolower(lowercase), toupper(uppercase), "][\\w_.]+"))
)))
}
}
# return list of names of packages starting with `lower` or `upper`
# Test this example once you complete above function
# Assuming your dataframe is called df
# This prints all package names starting with `z` or `Z`
# letter='a'
# print(paste0("^[", tolower(letter), toupper(letter), "][\\w]+"))
# str_extract(xml2_package_enlist_df$title, regex(paste0("^[", tolower(letter), toupper(letter), "][\\w]+")))
lowercase='z'
uppercase='Z'
head(getLetterList(xml2_package_enlist_df$title, uppercase, lowercase))
# xml2_package_enlist_df$title
# placeholder for Avg_length
# Avg_length = rep(0, 26)
# To do
letter='a'
Avg_length <- c()
# mean(nchar(na.omit(getLetterList(xml2_package_enlist_df$title, letter))))
for (letter in letters)
{
# print(mean(nchar(getLetterList(xml2_package_enlist_df$title, letter))))
Avg_length <- append(Avg_length
, values=mean(nchar(getLetterList(xml2_package_enlist_df$title, letter, letter)))
, after = length(Avg_length))
}
Avg_length
# to do
Num_upper <- c()
# na.omit(str_extract(getLetterList(xml2_package_enlist_df$title, uppercase='A', lowercase=''), regex("^[A-Z\\d.]+$")))
# regex("^[A-Z\\d.]+$") == regex("^[A-Z\\d.]+[A-Z\\d.]$")
# length(na.omit(c(NA))) #verify length 0 is also account
for (letter in letters)
{
#getLetterList(xml2_package_enlist_df$title, uppercase=letter, lowercase='')
Num_upper <- append(Num_upper
, length(
na.omit(str_extract(getLetterList(xml2_package_enlist_df$title, uppercase=letter, lowercase='')
, regex("^[A-Z\\d.]+$"))
))
, after=length(Num_upper)
)
}
Num_upper
Num_lower <- c()
for (letter in letters)
{
Num_lower <- append(Num_lower
, length(
na.omit(str_extract(getLetterList(xml2_package_enlist_df$title, uppercase='', lowercase=letter)
, regex("^[a-z\\d.]+$"))
))
, after=length(Num_lower)
)
}
Num_lower
# To do
Num_lower <- c()
str_detect(na.omit(str_extract(getLetterList(xml2_package_enlist_df$title, uppercase='A', lowercase=''), regex("^[A-Z\\d.]+$")))
, regex("[\\d]"))
for (letter in letters)
{
Num_lower <- append(Num_lower
, length(
na.omit(str_extract(getLetterList(xml2_package_enlist_df$title, uppercase='', lowercase=letter)
, regex("^[a-z\\d.]+$"))
))
, after=length(Num_lower)
)
}
Num_lower
Num_lower <- c()
for (letter in letters)
{
Num_lower <- append(Num_lower
, length(
na.omit(str_extract(getLetterList(xml2_package_enlist_df$title, uppercase='', lowercase=letter)
, regex("^[a-z\\d.]+$"))
))
, after=length(Num_lower)
)
}
Num_lower
# To do
Num_digit <- c()
str_detect(na.omit(str_extract(getLetterList(xml2_package_enlist_df$title, uppercase='A', lowercase=''), regex("^[A-Z\\d.]+$")))
, regex("[\\d]"))
str_match(na.omit(str_extract(getLetterList(xml2_package_enlist_df$title, uppercase='A', lowercase=''), regex("^[A-Z\\d.]+$")))
, regex("[\\d]"))
str_extract(na.omit(str_extract(getLetterList(xml2_package_enlist_df$title, uppercase='A', lowercase=''), regex("^[A-Z\\d.]+$")))
, regex("[\\d]"))
for (letter in letters)
{
Num_digit <- append(Num_digit
, length(
na.omit(str_extract(getLetterList(xml2_package_enlist_df$title, uppercase=letter, lowercase=letter)
, regex("[\\d]"))
))
, after=length(Num_digit)
)
}
Num_digit
Num_no_vowels <- c()
# any letters but vowels (a, e, i, o, u)
for (letter in letters)
{
Num_no_vowels <- append(Num_no_vowels
, length(
na.omit(str_extract(getLetterList(xml2_package_enlist_df$title, uppercase=letter, lowercase=letter)
, regex("[^aeiou]"))
))
, after=length(Num_no_vowels)
)
}
Num_no_vowels
str_extract(getLetterList(xml2_package_enlist_df$title, uppercase='A', lowercase='a')
str_extract(getLetterList(xml2_package_enlist_df$title, uppercase='A', lowercase='a')
str_extract(getLetterList(xml2_package_enlist_df$title, uppercase='A', lowercase='a')
, regex("[^aeiou]"))
str_extract(getLetterList(xml2_package_enlist_df$title, uppercase='A', lowercase='a')
, regex("[^aeiou]+"))
str_extract(getLetterList(xml2_package_enlist_df$title, uppercase='A', lowercase='a')
, regex("[^aeiouAEIOU]+"))
str_extract(getLetterList(xml2_package_enlist_df$title, uppercase='A', lowercase='a')
, regex("^[^aeiouAEIOU]+$"))
str_extract(getLetterList(xml2_package_enlist_df$title, uppercase='A', lowercase='a')
, regex("[^aeiouAEIOU]+$"))
str_extract(getLetterList(xml2_package_enlist_df$title, uppercase='A', lowercase='a')
, regex("^[^aeiouAEIOU]+$"))
Num_no_vowels <- c()
# any letters but vowels (a, e, i, o, u)
for (letter in letters)
{
Num_no_vowels <- append(Num_no_vowels
, length(
na.omit(str_extract(getLetterList(xml2_package_enlist_df$title, uppercase=letter, lowercase=letter)
, regex("^[^aeiouAEIOU]+$"))
))
, after=length(Num_no_vowels)
)
}
Num_no_vowels
# To do
Num_digits <- c()
# str_extract(na.omit(str_extract(getLetterList(xml2_package_enlist_df$title, uppercase='A', lowercase=''), regex("^[A-Z\\d.]+$")))
#           , regex("[\\d]"))
for (letter in letters)
{
Num_digits <- append(Num_digits
, length(
na.omit(str_extract(getLetterList(xml2_package_enlist_df$title, uppercase=letter, lowercase=letter)
, regex("[\\d]"))
))
, after=length(Num_digits)
)
}
Num_digits
cap_count_df
arrange(cap_count_df, desc(Var1))
arrange(cap_count_df, asec(Var1))
arrange(cap_count_df, asce(Var1))
?ararnge
?arrange
Num_frequency <- c()
for (letter in letters)
{
# print(mean(nchar(getLetterList(xml2_package_enlist_df$title, letter))))
Num_frequency <- append(Num_frequency
, values=length(getLetterList(xml2_package_enlist_df$title, letter, letter))
, after = length(Avg_length))
}
Num_frequency
for (letter in letters)
{
# print(mean(nchar(getLetterList(xml2_package_enlist_df$title, letter))))
Num_frequency <- append(Num_frequency
, values=length(getLetterList(xml2_package_enlist_df$title, letter, letter))
, after = length(Num_frequency))
Letter_order <- append(Letter_order
, values=paste(letter, "or", toupper(letter), sep=' ')
, after = length(Letter_order))
}
Letter_order <- c() #For 'Letter' column in cran_df
for (letter in letters)
{
# print(mean(nchar(getLetterList(xml2_package_enlist_df$title, letter))))
Num_frequency <- append(Num_frequency
, values=length(getLetterList(xml2_package_enlist_df$title, letter, letter))
, after = length(Num_frequency))
Letter_order <- append(Letter_order
, values=paste(letter, "or", toupper(letter), sep=' ')
, after = length(Letter_order))
}
Letter_order
cran_df <- data.frame("Letter"=Letter_order
, "Frequency"=Num_frequency
, "Avg_length"=Avg_length
, "Num_upper"=Num_upper
, "Num_lower"=Num_lower
, "Num_digits"=Num_digits
, "Num_no_vowels"=Num_no_vowels
)
length(Num_frequency)
Num_frequency <- c() #For 'Frequency' column in cran_df
Letter_order <- c() #For 'Letter' column in cran_df
for (letter in letters)
{
# print(mean(nchar(getLetterList(xml2_package_enlist_df$title, letter))))
Num_frequency <- append(Num_frequency
, values=length(getLetterList(xml2_package_enlist_df$title, letter, letter))
, after = length(Num_frequency))
Letter_order <- append(Letter_order
, values=paste(letter, "or", toupper(letter), sep=' ')
, after = length(Letter_order))
}
cran_df <- data.frame("Letter"=Letter_order
, "Frequency"=Num_frequency
, "Avg_length"=Avg_length
, "Num_upper"=Num_upper
, "Num_lower"=Num_lower
, "Num_digits"=Num_digits
, "Num_no_vowels"=Num_no_vowels
)
head(cran_df)
head(cran_df, n=3)
ggplot(data=cran_df, aes(x=Num_no_vowels, y=Avg_length)) +
geom_dotplot()
ggplot(data=cran_df, aes(x=Num_no_vowels, y=Avg_length)) +
geom_point()
ggplot(data=cran_df, aes(x=Num_no_vowels, y=Avg_length)) +
geom_point() +
labs(title="Association of Num_no_vowels and Avg_length"
x = "Num_no_vowels"
ggplot(data=cran_df, aes(x=Num_no_vowels, y=Avg_length)) +
geom_point() +
labs(title="Association of Num_no_vowels and Avg_length"
, x = "Num_no_vowels"
, y = "Avg_length"
)
ggplot(data=cran_df, aes(x=Num_no_vowels, y=Avg_length)) +
geom_point() +
labs(title="Association of Num_no_vowels and Avg_length"
, x = "Num_no_vowels"
, y = "Avg_length"
) +
stat_smooth(method = "lm",
col = "#C42126",
se = FALSE,
size = 1)
ggplot(data=cran_df, aes(x=Num_no_vowels, y=Avg_length)) +
geom_point() +
labs(title="Association of Num_no_vowels and Avg_length"
, x = "Num_no_vowels"
, y = "Avg_length"
) +
# fitting a line to observe correlation
stat_smooth(method = "lm"
, col="blue"
, se=F
, size=1
)
ggplot(data=cran_df, aes(x=Num_no_vowels, y=Avg_length, col=Letter)) +
geom_point() +
labs(title="Association of Num_no_vowels and Avg_length"
, x = "Num_no_vowels"
, y = "Avg_length"
) +
# fitting a line to observe correlation
stat_smooth(method = "lm"
, col="blue"
, se=F
, size=1
)
?stat_smooth
ggplot(data=cran_df, aes(x=Num_no_vowels, y=Avg_length, col=Letter)) +
geom_point() +
labs(title="Association of Num_no_vowels and Avg_length"
, x = "Num_no_vowels"
, y = "Avg_length"
) +
# fitting a line to observe correlation
stat_smooth(method = "lm"
, col="blue"
, se=T #confidence interval
, size=1
,
)
ggplot(data=cran_df, aes(x=Num_no_vowels, y=log(Avg_length), col=Letter)) +
geom_point() +
labs(title="Association of Num_no_vowels and Avg_length"
, x = "Num_no_vowels"
, y = "Avg_length"
) +
# fitting a line to observe association
stat_smooth(method = "lm"
, col="blue"
, se=T #confidence interval
, size=1
,
)
ggplot(data=cran_df, aes(x=log(Num_no_vowels), y=Avg_length, col=Letter)) +
geom_point() +
labs(title="Association of Num_no_vowels and Avg_length"
, x = "Num_no_vowels"
, y = "Avg_length"
) +
# fitting a line to observe association
stat_smooth(method = "lm"
, col="blue"
, se=T #confidence interval
, size=1
,
)
ggplot(data=cran_df, aes(x=Num_no_vowels, y=Avg_length, col=Letter)) +
geom_point() +
labs(title="Association of Num_no_vowels and Avg_length"
, x = "Num_no_vowels"
, y = "Avg_length"
) +
# fitting a line to observe association
stat_smooth(method = "lm"
, col="blue"
, se=T #confidence interval
, size=1
,
)
#https://www.guru99.com/r-scatter-plot-ggplot2.html
ggplot(data=cran_df, aes(x=Num_no_vowels, y=Avg_length, col=Letter)) +
geom_point() +
labs(title="Association of Num_no_vowels and Avg_length"
, x = "Num_no_vowels"
, y = "Avg_length"
) +
# fitting a line to observe association
stat_smooth(method = "lm"
, col="blue"
, se=T #confidence interval
, size=1
,
)
print("shows weak association, but log scaling 'Num_no_vowels' may strengthen the association.")
str_extract(xml2_package_enlist_df$title, regex("^[^aeiouAEIOU]+$"))
length(na.omit(str_extract(xml2_package_enlist_df$title, regex("^[^aeiouAEIOU]+$"))))
nchar(na.omit(str_extract(xml2_package_enlist_df$title, regex("^[^aeiouAEIOU]+$"))))
title_length_no_vowels <- nchar(na.omit(str_extract(xml2_package_enlist_df$title, regex("^[^aeiouAEIOU]+$"))))
title_length_no_vowels <- nchar(na.omit(str_extract(xml2_package_enlist_df$title, regex("^[^aeiouAEIOU]+$"))))
title_length_no_vowels
mean(title_length_no_vowels)
summary(title_length_no_vowels)
My interest in biology and computer science lead me into the field of bioinformatics/computational biology. Currently focus on development and application of alignment-free approaches that view biological sequences (nucleotides and admino acids) as information that relies on a choice of descriptors (language) more than models.
